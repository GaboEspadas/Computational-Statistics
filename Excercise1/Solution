"""

Series 1 Simple Linear Regression
Author: Gabriel Espadas

"""

import matplotlib.mlab as mlab
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.linear_model import LinearRegression


## 2 - a)
# Write a sequence of R-commands which randomly generates 100 times a vector of y-values according
# to the above model with the given x-values and generates a vector of slopes of the regression lines.

# The low level api is quite bad as it is very general. Better not to use it.
def training_low_level_api(doit):
    if doit:
        x_train = np.arange(1, 41)
        n_samples = x_train.shape[0]
        y_train = 2 * x_train + 1 + np.random.normal(0, scale=5, size=n_samples)

        # tf graph input
        X = tf.placeholder("float")
        Y = tf.placeholder("float")

        # model weights
        W = tf.Variable(np.random.rand(), name="weights")
        b = tf.Variable(np.random.rand(), name="bias")

        # Linear model
        pred = tf.add(tf.multiply(X, W), b)

        # Mean Squared Error
        cost = tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * n_samples)

        # Gradient Descent
        # Parameters
        learning_rate = 0.01
        training_epochs = 1000
        display_step = 50
        optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)

        # Initialize
        init = tf.global_variables_initializer()

        # Training
        with tf.Session() as sess:
            sess.run(init)

            for epoch in range(training_epochs):
                for (x, y) in zip(x_train, y_train):
                    sess.run(optimizer, feed_dict={X: x, Y: y})

                # Display logs per epoch step
                if (epoch + 1) % display_step == 0:
                    c = sess.run(cost, feed_dict={X: x_train, Y: y_train})
                print("Epoch:", '%04d' % (epoch + 1), "cost=", "{:.9f}".format(c), \
                      "W=", sess.run(W), "b=", sess.run(b))

            print("Optimization Finished!")
            training_cost = sess.run(cost, feed_dict={X: x_train, Y: y_train})
            print("Training cost=", training_cost, "W=", sess.run(W), "b=", sess.run(b), '\n')

            # Graphic display
            plt.plot(x_train, y_train, 'ro', label='Original data')
            plt.plot(x_train, sess.run(W) * x_train + sess.run(b), label='Fitted line')
            plt.legend()
            plt.show()


## Now lets try the high level api. UPDATE: I CANNOT EXTRACT THE COEFFICIENTS! I may still use some cheap tricks
## for example predicting at x = 0 and x = 1 but better use something else
def train_using_high_level():
    x_train = np.arange(1, 41)
    n_samples = x_train.shape[0]
    y_train = 2 * x_train + 1 + np.random.normal(0, scale=5, size=n_samples)
    x_train = pd.DataFrame(x_train, columns=["x"])
    y_train = pd.DataFrame(y_train, columns=["y"])

    def input_fn(features, labels):
        dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))
        dataset = dataset.batch(10)
        return dataset.make_one_shot_iterator().get_next()

    my_feature_columns = []
    for key in x_train.keys():
        my_feature_columns.append(tf.feature_column.numeric_column(key=key))

        # for i in range(100):
    linear_model = tf.estimator.LinearRegressor(feature_columns=my_feature_columns)
    linear_model.train(input_fn=lambda: input_fn(x_train, y_train), steps=1000)
    model_vars = tf.get_collection(tf.GraphKeys.MODEL_VARIABLES)
    model_vars


## Go for something simpler
x_train = np.arange(1, 41).reshape(40, 1)
n_samples = x_train.shape[0]

slopes =[]
linear_model = LinearRegression()

for i in range(100):
    y_train = 2 * x_train + 1 + np.random.normal(0, scale=5, size=n_samples).reshape((40, 1))
    linear_model.fit(X=x_train, y=y_train)
    slopes.append(linear_model.coef_[0][0])

mu = 2
extended_x = np.concatenate((np.ones(n_samples).reshape(40,1),x_train),axis=1)
xt_x = np.dot(extended_x.transpose(),extended_x)
sigma = 5*np.sqrt(np.linalg.inv(xt_x)[1,1])
x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)

plt.hist(np.asanyarray(slopes),density=True)
plt.plot(x,mlab.normpdf(x, mu, sigma))
plt.show()